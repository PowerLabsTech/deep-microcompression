{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 Experiment Verification with NAS\n",
    "\n",
    "This notebook verifies the LeNet-5 experiment using Neural Architecture Search (NAS) to find optimal pruning configurations, followed by quantization.\n",
    "\n",
    "## Overview\n",
    "1. **Baseline Model:** Train or load the baseline LeNet-5 model.\n",
    "2. **NAS (Neural Architecture Search):** \n",
    "    - Generate random pruning configurations.\n",
    "    - Train an `Estimator` (MLP) to predict accuracy based on configuration.\n",
    "    - Use brute-force search with the estimator to find the best configuration under constraints (e.g., >99% relative accuracy).\n",
    "3. **Pruning & Quantization:** Apply the optimal configuration found by NAS to the model and verify performance.\n",
    "\n",
    "**Verification:** Prune, Quantize, and Retrain (QAT) the model using the found configuration to verify the results (Table I)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    from torch.utils import data\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "except ImportError:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    from torch.utils import data\n",
    "    from torchvision import datasets, transforms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "try:\n",
    "    from development import (\n",
    "        Sequential,\n",
    "        Conv2d,\n",
    "        BatchNorm2d,\n",
    "        ReLU,\n",
    "        MaxPool2d,\n",
    "        Flatten,\n",
    "        Linear,\n",
    "        EarlyStopper,\n",
    "        QuantizationGranularity,\n",
    "        QuantizationScheme,\n",
    "        Estimator\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import 'development' module. Check path setup.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "INPUT_SHAPE = (1, 28, 28)\n",
    "DATASET_DIR = \"../../Datasets\"\n",
    "LENET5_FILE = \"lenet5_state_dict.pth\"\n",
    "NAS_PARAMS_FILE = \"nas_parameters.pth\"\n",
    "LUCKY_NUMBER = 25\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders():\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.RandomCrop((24, 24)),\n",
    "        transforms.Resize(INPUT_SHAPE[1:]),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    train_set = datasets.MNIST(DATASET_DIR, train=True, download=True, transform=data_transform)\n",
    "    test_set = datasets.MNIST(DATASET_DIR, train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "    test_loader = data.DataLoader(test_set, batch_size=32, shuffle=False, num_workers=os.cpu_count())\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def accuracy_fun(y_pred, y_true):\n",
    "    return (y_pred.argmax(dim=1) == y_true).to(torch.float).mean().item() * 100\n",
    "\n",
    "mnist_train_loader, mnist_test_loader = get_data_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and Training the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lenet5_model():\n",
    "    return Sequential(\n",
    "        Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=(2, 2, 2, 2), bias=True),\n",
    "        BatchNorm2d(num_features=6),\n",
    "        ReLU(),\n",
    "        MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "        BatchNorm2d(num_features=16),\n",
    "        ReLU(),\n",
    "        MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        Flatten(),\n",
    "        Linear(in_features=16*5*5, out_features=84, bias=True),\n",
    "        ReLU(),\n",
    "        Linear(in_features=84, out_features=10, bias=True)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "lenet5_model = get_lenet5_model()\n",
    "\n",
    "# Train or Load Baseline\n",
    "if os.path.exists(LENET5_FILE):\n",
    "    print(f\"Loading baseline from {LENET5_FILE}...\")\n",
    "    lenet5_model.load_state_dict(torch.load(LENET5_FILE, map_location=DEVICE))\n",
    "else:\n",
    "    print(\"Training baseline model...\")\n",
    "    early_stopper = EarlyStopper(\n",
    "        monitor_metric=\"validation_loss\", delta=1e-7, mode=\"min\", patience=4, restore_best_state_dict=True\n",
    "    )\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizer_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    \n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 20, criterion_fun, optimizer_fun,\n",
    "        validation_dataloader=mnist_test_loader, metrics={\"acc\": accuracy_fun},\n",
    "        device=DEVICE\n",
    "    )\n",
    "    torch.save(lenet5_model.state_dict(), LENET5_FILE)\n",
    "\n",
    "print(f\"Baseline Accuracy: {lenet5_model.evaluate(mnist_test_loader, {'acc': accuracy_fun}, device=DEVICE)['acc']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating NAS Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generatng NAS Data ---\")\n",
    "nas_parameters = []\n",
    "\n",
    "with_training = True\n",
    "\n",
    "if os.path.exists(NAS_PARAMS_FILE):\n",
    "    print(f\"Loading NAS parameters from {NAS_PARAMS_FILE}...\")\n",
    "    nas_parameters = torch.load(NAS_PARAMS_FILE)\n",
    "    if len(nas_parameters) != 1000:\n",
    "        print(\"Warning: Expected 1000 params, got\", len(nas_parameters))\n",
    "else:\n",
    "    print(\"Running NAS Sampling (this may take time)...\")\n",
    "    # Using get_nas_prune_channel from Sequential (refactored earlier)\n",
    "    nas_parameters = lenet5_model.get_nas_prune_channel(\n",
    "        INPUT_SHAPE, mnist_test_loader, accuracy_fun, DEVICE, \n",
    "        num_data=1000, train=with_training, train_dataloader=mnist_train_loader, epochs=2, \n",
    "        criterion_fun=nn.CrossEntropyLoss(), random_seed=LUCKY_NUMBER\n",
    "    )\n",
    "    torch.save(nas_parameters, NAS_PARAMS_FILE)\n",
    "    \n",
    "print(f\"Generated {len(nas_parameters)} NAS samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the NAS Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Accuracy Estimator ---\")\n",
    "estimator = Estimator(nas_parameters, device=DEVICE, hidden_dim=[128, 128, 128], dropout=.75)\n",
    "estimator_history = estimator.fit(epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(estimator_history[\"validation_abs\"], label=\"val_abs\")\n",
    "axes[0].plot(estimator_history[\"train_abs\"], label=\"train_abs\")\n",
    "axes[0].legend(); axes[0].set_title(\"MAE Loss\")\n",
    "\n",
    "axes[1].plot(estimator_history[\"validation_mse\"], label=\"val_mse\")\n",
    "axes[1].plot(estimator_history[\"train_mse\"], label=\"train_mse\")\n",
    "axes[1].legend(); axes[1].set_title(\"MSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_search_prune_config(\n",
    "    model,\n",
    "    estimator,\n",
    "    input_shape,\n",
    "    condition=lambda m, s, r, c: True,                 \n",
    "    objective=lambda m, s, r, c: m,                  \n",
    "    maximize=True,                   \n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic brute-force search engine.\n",
    "    \"\"\"\n",
    "    best_value = float(\"-inf\") if maximize else float(\"inf\")\n",
    "    best_comb = None\n",
    "    best_result_info = None\n",
    "\n",
    "    # compute baseline size\n",
    "    original_size = model.get_size_in_bytes()\n",
    "    # Dummy prediction to get baseline metric scaling if needed\n",
    "    original_metric = estimator.predict(torch.Tensor([0]*len(model.get_prune_channel_possible_hyperparameters())).unsqueeze(0))\n",
    "\n",
    "    def get_all_combinations(flat_dict):\n",
    "        keys = list(flat_dict.keys())\n",
    "        vals = list(flat_dict.values())\n",
    "        for combo in itertools.product(*vals):\n",
    "            yield {k: v for k, v in zip(keys, combo)}\n",
    "\n",
    "    print(\"Starting Brute Force Search...\")\n",
    "    # iterate search space\n",
    "    for comb in get_all_combinations(model.get_prune_channel_possible_hyperparameters()):\n",
    "\n",
    "        # predict metric (Accuracy)\n",
    "        # Note: Estimator input order must match NAS generation order\n",
    "        # Normalized metric (relative to original)\n",
    "        metric = estimator.predict(\n",
    "            torch.Tensor(list(comb.values())).unsqueeze(0)\n",
    "        ) / original_metric\n",
    "        \n",
    "        # create compressed model to measure size/ram\n",
    "        compressed = model.init_compress({\n",
    "            \"prune_channel\": {\"sparsity\": comb, \"metric\": \"l2\"}\n",
    "        }, input_shape)\n",
    "\n",
    "        size = compressed.get_size_in_bytes() / original_size\n",
    "        # -------- HARD FILTERS --------\n",
    "        if not condition(metric, size, comb):\n",
    "            continue\n",
    "\n",
    "        # -------- OBJECTIVE VALUE --------\n",
    "        obj = objective(metric, size, comb)\n",
    "\n",
    "        if (maximize and obj > best_value) or (not maximize and obj < best_value):\n",
    "            best_value = obj\n",
    "            best_comb = comb\n",
    "            best_result_info = [metric, size]\n",
    "            if verbose:\n",
    "                print(f\"âœ” New best: obj={obj:.4f}, metric={metric:.2f}, size_ratio={size:.4f}, comb={comb}\")\n",
    "\n",
    "    return best_comb, best_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Searching for smallest config with Accuracy > 98.0% ...\")\n",
    "# Note: condition depends on estimator scale. Assuming estimator predicts 0-100 accuracy.\n",
    "best_comb, best_result_info = brute_force_search_prune_config(\n",
    "    lenet5_model,\n",
    "    estimator,\n",
    "    INPUT_SHAPE,\n",
    "    condition=lambda metric, size, comb: metric > .989, \n",
    "    objective= lambda metric, size, comb: size, \n",
    "    maximize=False, # Minimize Size\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nOptimal Configuration Found: {best_comb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
