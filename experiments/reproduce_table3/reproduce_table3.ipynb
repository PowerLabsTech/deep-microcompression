{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-13 TFLite vs. DMC Comparison Guide\n",
    "\n",
    "This notebook reproduces the VGG-13 experiments comparing TensorFlow Lite (TFLite) and Deep Microcompression (DMC) performanc (Table 3) from the \"Deep Microcompression\" paper.\n",
    "\n",
    "## Required File Structure\n",
    "\n",
    "This script assumes it is located within the original project's directory structure under the experiments directory. The development module must be accessible two levels up.\n",
    "\n",
    "## Experiment Overview\n",
    "\n",
    "The experiment compares accuracy and model size across three quantization schemes:\n",
    "1. **Float32 (Baseline):** No quantization.\n",
    "2. **Dynamic Quantization:** Weights are quantized, activations dynamically quantized at runtime.\n",
    "3. **Static Quantization (Int8):** Weights and activations are quantized using calibration data.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Source of Truth:** Uses a pre-trained VGG-13 (Batch Norm) model from PyTorch Hub (`cifar100_vgg13_bn`).\n",
    "2. **Weight Transfer:** Copies weights from the PyTorch model to an equivalent TensorFlow/Keras model to ensure an exact baseline match.\n",
    "3. **DMC Conversion:** Converts the PyTorch model to a DMC `Sequential` model.\n",
    "4. **TFLite Conversion:** Converts the Keras model to TFLite flatbuffers using standard optimization flags.\n",
    "5. **Evaluation:** Both frameworks evaluate on the same CIFAR-100 test set. PyTorch is forced to CPU to match the TFLite execution environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Force TensorFlow to CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-03 12:22:37.794550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764760957.808354   20604 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764760957.812630   20604 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764760957.823182   20604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764760957.823196   20604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764760957.823197   20604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764760957.823199   20604 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils import data\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "except ImportError:\n",
    "    %pip install torch torchvision tqdm\n",
    "\n",
    "    import numpy as np\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils import data\n",
    "    from torchvision import datasets, transforms\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the script is in 'project_root/experiments/vgg_comparison'\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "try:\n",
    "    from development.models.utils import convert_from_sequential_torch_to_dmc\n",
    "    from development import (\n",
    "        QuantizationScheme,\n",
    "        QuantizationGranularity\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import the 'development' module.\")\n",
    "    print(\"Please ensure this script is run from the correct directory\")\n",
    "    print(\"and the 'development' module is in the project root ('../../').\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Constants ---\n",
    "DEVICE = \"cpu\"  # Force PyTorch to CPU for fair comparison with TFLite CPU execution\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "INPUT_SHAPE_TORCH = (1, 3, 32, 32)\n",
    "INPUT_SHAPE_TF = (32, 32, 3)\n",
    "DATASET_DIR = \"../../Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUCKY_NUMBER = 25\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "tf.random.set_seed(LUCKY_NUMBER)\n",
    "np.random.seed(LUCKY_NUMBER)\n",
    "random.seed(LUCKY_NUMBER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading CIFAR-100 Dataset\n",
    "We load the dataset with the specific normalization statistics required by the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders():\n",
    "    \"\"\"Loads CIFAR-100 data for both PyTorch and TF evaluation.\"\"\"\n",
    "    print(\"Loading CIFAR-100 dataset...\")\n",
    "    \n",
    "    # Normalization must match the pre-trained model's requirements\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.5071, 0.4867, 0.4408),\n",
    "            std=(0.2675, 0.2565, 0.2761)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    cifar100_train_dataset = datasets.CIFAR100(DATASET_DIR, train=True, download=True, transform=data_transform)\n",
    "    cifar100_test_dataset = datasets.CIFAR100(DATASET_DIR, train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    cifar100_train_loader = data.DataLoader(cifar100_train_dataset, batch_size=256, shuffle=True, num_workers=os.cpu_count())\n",
    "    cifar100_test_loader = data.DataLoader(cifar100_test_dataset, batch_size=256, shuffle=False, num_workers=os.cpu_count())\n",
    "    \n",
    "    return cifar100_train_loader, cifar100_test_loader, cifar100_train_dataset, cifar100_test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the TensorFlow Model & Weight Transfer\n",
    "To compare against TFLite, we must first construct an equivalent Keras model and copy the weights from the PyTorch source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_vgg13_bn_equivalent():\n",
    "    \"\"\"Creates a Keras Sequential model that mirrors the PyTorch VGG13_BN architecture.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=INPUT_SHAPE_TF),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding='same', name='conv_0'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_1', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_2'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding='same', name='conv_3'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_4', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_5'),\n",
    "        tf.keras.layers.MaxPooling2D(2, strides=2, name='pool_6'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding='same', name='conv_7'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_8', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_9'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding='same', name='conv_10'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_11', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_12'),\n",
    "        tf.keras.layers.MaxPooling2D(2, strides=2, name='pool_13'),\n",
    "        tf.keras.layers.Conv2D(256, 3, padding='same', name='conv_14'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_15', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_16'),\n",
    "        tf.keras.layers.Conv2D(256, 3, padding='same', name='conv_17'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_18', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_19'),\n",
    "        tf.keras.layers.MaxPooling2D(2, strides=2, name='pool_20'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding='same', name='conv_21'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_22', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_23'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding='same', name='conv_24'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_25', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_26'),\n",
    "        tf.keras.layers.MaxPooling2D(2, strides=2, name='pool_27'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding='same', name='conv_28'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_29', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_30'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding='same', name='conv_31'),\n",
    "        tf.keras.layers.BatchNormalization(name='bn_32', epsilon=1e-5),\n",
    "        tf.keras.layers.ReLU(name='relu_33'),\n",
    "        tf.keras.layers.MaxPooling2D(2, strides=2, name='pool_34'),\n",
    "        tf.keras.layers.Flatten(name='flat_35'),\n",
    "        tf.keras.layers.Dense(512, name='fc_36'),\n",
    "        tf.keras.layers.ReLU(name='relu_37'),\n",
    "        tf.keras.layers.Dropout(0.5, name='drop_38'),\n",
    "        tf.keras.layers.Dense(512, name='fc_39'),\n",
    "        tf.keras.layers.ReLU(name='relu_40'),\n",
    "        tf.keras.layers.Dropout(0.5, name='drop_41'),\n",
    "        tf.keras.layers.Dense(100, name='fc_42')\n",
    "    ], name=\"Custom_VGG13_BN\")\n",
    "\n",
    "def copy_torch_to_tf(pt_state_dict, tf_model):\n",
    "    \"\"\"Copies weights from a PyTorch state_dict to the Keras model.\"\"\"\n",
    "    print(\"Copying weights from PyTorch to Keras...\")\n",
    "    # Mapping of PyTorch Layer Index to Keras Layer Name\n",
    "    conv_layers = [(0, 'conv_0'), (3, 'conv_3'), (7, 'conv_7'), (10, 'conv_10'),\n",
    "                   (14, 'conv_14'), (17, 'conv_17'), (21, 'conv_21'), (24, 'conv_24'),\n",
    "                   (28, 'conv_28'), (31, 'conv_31')]\n",
    "    bn_layers = [(1, 'bn_1'), (4, 'bn_4'), (8, 'bn_8'), (11, 'bn_11'),\n",
    "                 (15, 'bn_15'), (18, 'bn_18'), (22, 'bn_22'), (25, 'bn_25'),\n",
    "                 (29, 'bn_29'), (32, 'bn_32')]\n",
    "    fc_layers = [(36, 'fc_36'), (39, 'fc_39'), (42, 'fc_42')]\n",
    "\n",
    "    # Copy Convolution Weights\n",
    "    for pt_idx, tf_name in conv_layers:\n",
    "        tf_layer = tf_model.get_layer(tf_name)\n",
    "        pt_weight = pt_state_dict[f'{pt_idx}.weight'].detach().numpy()\n",
    "        pt_bias = pt_state_dict[f'{pt_idx}.bias'].detach().numpy()\n",
    "        tf_weight = np.transpose(pt_weight, (2, 3, 1, 0)) # PT (out, in, H, W) -> TF (H, W, in, out)\n",
    "        tf_layer.set_weights([tf_weight, pt_bias])\n",
    "\n",
    "    # Copy BatchNorm Weights\n",
    "    for pt_idx, tf_name in bn_layers:\n",
    "        tf_layer = tf_model.get_layer(tf_name)\n",
    "        gamma = pt_state_dict[f'{pt_idx}.weight'].detach().numpy()\n",
    "        beta = pt_state_dict[f'{pt_idx}.bias'].detach().numpy()\n",
    "        moving_mean = pt_state_dict[f'{pt_idx}.running_mean'].detach().numpy()\n",
    "        moving_variance = pt_state_dict[f'{pt_idx}.running_var'].detach().numpy()\n",
    "        tf_layer.set_weights([gamma, beta, moving_mean, moving_variance])\n",
    "\n",
    "    # Copy Linear Weights\n",
    "    for pt_idx, tf_name in fc_layers:\n",
    "        tf_layer = tf_model.get_layer(tf_name)\n",
    "        pt_weight = pt_state_dict[f'{pt_idx}.weight'].detach().numpy()\n",
    "        pt_bias = pt_state_dict[f'{pt_idx}.bias'].detach().numpy()\n",
    "        tf_weight = np.transpose(pt_weight, (1, 0)) # PT (out, in) -> TF (in, out)\n",
    "        tf_layer.set_weights([tf_weight, pt_bias])\n",
    "    \n",
    "    print(\"Weight copy complete.\")\n",
    "    return tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tf_to_tflite(tf_model, scheme=QuantizationScheme.NONE, train_loader=None):\n",
    "    \"\"\"Converts Keras model to TFLite flatbuffer.\"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "    \n",
    "    if scheme == QuantizationScheme.DYNAMIC:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "    if scheme == QuantizationScheme.STATIC:\n",
    "        def representative_dataset():\n",
    "            # Use 100 batches from the PyTorch train loader\n",
    "            for i, (batch_images, _) in enumerate(train_loader):\n",
    "                if i >= 100: break\n",
    "                # Permute (B, C, H, W) to TF-style (B, H, W, C)\n",
    "                yield [batch_images.permute(0, 2, 3, 1).numpy().astype(np.float32)]\n",
    "                \n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "\n",
    "    return converter.convert()\n",
    "\n",
    "def get_tflite_model_accuracy(tflite_model, test_dataset, scheme=QuantizationScheme.NONE):\n",
    "    \"\"\"Evaluates a TFLite flatbuffer model using the PyTorch test dataset.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    tflite_predicted = []\n",
    "    actual_label = []\n",
    "\n",
    "    for image, label in tqdm(test_dataset, desc=f\"Evaluating TFLite ({scheme.name})\"):\n",
    "        image_np = image.unsqueeze(0).permute(0, 2, 3, 1).numpy() # (1, H, W, C)\n",
    "        \n",
    "        if scheme == QuantizationScheme.STATIC:\n",
    "            scale, zero_point = input_details[\"quantization\"]\n",
    "            image_np = ((image_np / scale) + zero_point).astype(np.int8)\n",
    "        \n",
    "        interpreter.set_tensor(input_details[\"index\"], image_np)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[\"index\"])\n",
    "        \n",
    "        tflite_predicted.append(np.argmax(output_data))\n",
    "        actual_label.append(label)\n",
    "\n",
    "    tflite_predicted = np.array(tflite_predicted)\n",
    "    actual_label = np.array(actual_label)\n",
    "    return (tflite_predicted == actual_label).mean()\n",
    "\n",
    "def top1_acc_fun(y_pred, y_true):\n",
    "    return (y_pred.argmax(dim=1) == y_true).to(torch.float).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-100 dataset...\n",
      "Loading pre-trained VGG-13 BN from PyTorch Hub...\n",
      "\n",
      "--- Creating TF/Keras Baseline ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "2025-12-03 12:22:42.334344: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying weights from PyTorch to Keras...\n",
      "Weight copy complete.\n",
      "\n",
      "--- Creating DMC Baseline ---\n"
     ]
    }
   ],
   "source": [
    "# --- Initialization ---\n",
    "results = []\n",
    "\n",
    "# 1. Load Data\n",
    "train_loader, test_loader, train_dataset, test_dataset = get_data_loaders()\n",
    "\n",
    "# 2. Load PyTorch Baseline (The Source of Truth)\n",
    "print(\"Loading pre-trained VGG-13 BN from PyTorch Hub...\")\n",
    "pt_vgg13_hub = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg13_bn\", pretrained=True, verbose=False)\n",
    "# Flatten the nested structure for easier conversion\n",
    "pt_vgg13_full = (pt_vgg13_hub.features + nn.Sequential(nn.Flatten()) + pt_vgg13_hub.classifier).eval()\n",
    "pt_state_dict = pt_vgg13_full.state_dict()\n",
    "\n",
    "# 3. Create Equivalent Models\n",
    "print(\"\\n--- Creating TF/Keras Baseline ---\")\n",
    "tf_model = create_tf_vgg13_bn_equivalent()\n",
    "tf_model = copy_torch_to_tf(pt_state_dict, tf_model)\n",
    "\n",
    "print(\"\\n--- Creating DMC Baseline ---\")\n",
    "dmc_base_model = convert_from_sequential_torch_to_dmc(pt_vgg13_full).to(DEVICE)\n",
    "dmc_metrics = {\"top1acc\": top1_acc_fun}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO QUANTIZATION (Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 2: Running Float32 (No Quantization) Comparison ---\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpeepi3_0e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpeepi3_0e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpeepi3_0e'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139506701965200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701966544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701965584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701966160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701975184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701975376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701964240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701961936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701960400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701961168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701962128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699370960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699370768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699375184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1764760964.406058   20604 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1764760964.406075   20604 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1764760964.433177   20604 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Evaluating TFLite (NONE): 100%|██████████| 10000/10000 [01:32<00:00, 107.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Float: 74.63% | 39936240 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMC Float:    74.63% | 39949968 bytes\n"
     ]
    }
   ],
   "source": [
    "# --- STAGE 2: NO QUANTIZATION (Float32) ---\n",
    "print(\"\\n--- STAGE 2: Running Float32 (No Quantization) Comparison ---\")\n",
    "\n",
    "# TFLite (Float)\n",
    "tflite_float_model = convert_tf_to_tflite(tf_model, QuantizationScheme.NONE)\n",
    "tflite_float_acc = get_tflite_model_accuracy(tflite_float_model, test_dataset, QuantizationScheme.NONE)\n",
    "tflite_float_size = len(tflite_float_model)\n",
    "results.append((\"TFLite (Float32)\", tflite_float_acc, tflite_float_size))\n",
    "print(f\"TFLite Float: {tflite_float_acc*100:.2f}% | {tflite_float_size} bytes\")\n",
    "\n",
    "# DMC (Float)\n",
    "dmc_float_model = dmc_base_model.init_compress({\n",
    "    \"quantize\": {\"scheme\": QuantizationScheme.NONE, \"bitwidth\": None, \"granularity\": None}\n",
    "    }, INPUT_SHAPE_TORCH)\n",
    "dmc_float_eval = dmc_float_model.evaluate(test_loader, dmc_metrics, device=DEVICE)\n",
    "dmc_float_size = dmc_float_model.get_size_in_bits() // 8\n",
    "results.append((\"DMC (Float32)\", dmc_float_eval['top1acc'], dmc_float_size))\n",
    "print(f\"DMC Float:    {dmc_float_eval['top1acc']*100:.2f}% | {dmc_float_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DYNAMIC QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 3: Running Dynamic Quantization Comparison ---\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpday746z8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpday746z8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpday746z8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139506701965200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701966544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701965584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701966160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701975184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701975376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701964240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701961936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701960400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701961168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701962128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699370960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699370768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699375184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1764761100.850153   20604 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1764761100.850167   20604 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "Evaluating TFLite (DYNAMIC): 100%|██████████| 10000/10000 [00:22<00:00, 444.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Dynamic: 74.62% | 10052520 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMC Dynamic:    74.32% | 10017412 bytes\n"
     ]
    }
   ],
   "source": [
    "# --- STAGE 3: DYNAMIC QUANTIZATION ---\n",
    "print(\"\\n--- STAGE 3: Running Dynamic Quantization Comparison ---\")\n",
    "\n",
    "# TFLite (Dynamic)\n",
    "tflite_dyn_model = convert_tf_to_tflite(tf_model, QuantizationScheme.DYNAMIC)\n",
    "tflite_dyn_acc = get_tflite_model_accuracy(tflite_dyn_model, test_dataset, QuantizationScheme.DYNAMIC)\n",
    "tflite_dyn_size = len(tflite_dyn_model)\n",
    "results.append((\"TFLite (Dynamic)\", tflite_dyn_acc, tflite_dyn_size))\n",
    "print(f\"TFLite Dynamic: {tflite_dyn_acc*100:.2f}% | {tflite_dyn_size} bytes\")\n",
    "\n",
    "# DMC (Dynamic)\n",
    "dmc_dyn_model = dmc_base_model.init_compress({\n",
    "    \"quantize\": {\"scheme\": QuantizationScheme.DYNAMIC, \"bitwidth\": 8, \"granularity\": QuantizationGranularity.PER_TENSOR}\n",
    "}, INPUT_SHAPE_TORCH)\n",
    "dmc_dyn_eval = dmc_dyn_model.evaluate(test_loader, dmc_metrics, device=DEVICE)\n",
    "dmc_dyn_size = dmc_dyn_model.get_size_in_bits() // 8\n",
    "results.append((\"DMC (Dynamic)\", dmc_dyn_eval['top1acc'], dmc_dyn_size))\n",
    "print(f\"DMC Dynamic:    {dmc_dyn_eval['top1acc']*100:.2f}% | {dmc_dyn_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAGE 3: STATIC QUANTIZATION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 4: Running Static Quantization (INT8) Comparison ---\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbjb303ih/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbjb303ih/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpbjb303ih'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139506701965200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701966544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701965584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701966160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701968272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701969040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701970768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701971536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701967312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701975184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701972496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701974416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701975376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701964240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701961936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701960400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701961168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701973648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506701962128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699370960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699370768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699371344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699372112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699373072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699375184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139506699374992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1764761171.390151   20604 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1764761171.390164   20604 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "Evaluating TFLite (STATIC): 100%|██████████| 10000/10000 [00:22<00:00, 450.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Static: 74.44% | 10102360 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMC Static:    74.32% | 10017504 bytes\n"
     ]
    }
   ],
   "source": [
    "# --- STAGE 4: STATIC QUANTIZATION ---\n",
    "print(\"\\n--- STAGE 4: Running Static Quantization (INT8) Comparison ---\")\n",
    "\n",
    "# TFLite (Static)\n",
    "tflite_static_model = convert_tf_to_tflite(tf_model, QuantizationScheme.STATIC, train_loader)\n",
    "tflite_static_acc = get_tflite_model_accuracy(tflite_static_model, test_dataset, QuantizationScheme.STATIC)\n",
    "tflite_static_size = len(tflite_static_model)\n",
    "results.append((\"TFLite (Static)\", tflite_static_acc, tflite_static_size))\n",
    "print(f\"TFLite Static: {tflite_static_acc*100:.2f}% | {tflite_static_size} bytes\")\n",
    "\n",
    "# DMC (Static)\n",
    "calib_data_torch = next(iter(train_loader))[0].to(DEVICE)\n",
    "dmc_static_model = dmc_base_model.init_compress({\n",
    "    \"quantize\": {\"scheme\": QuantizationScheme.STATIC, \"bitwidth\": 8, \"granularity\": QuantizationGranularity.PER_TENSOR}\n",
    "}, INPUT_SHAPE_TORCH, calibration_data=calib_data_torch)\n",
    "dmc_static_eval = dmc_static_model.evaluate(test_loader, dmc_metrics, device=DEVICE)\n",
    "dmc_static_size = dmc_static_model.get_size_in_bits() // 8\n",
    "results.append((\"DMC (Static)\", dmc_static_eval['top1acc'], dmc_static_size))\n",
    "print(f\"DMC Static:    {dmc_static_eval['top1acc']*100:.2f}% | {dmc_static_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- REPRODUCTION FINISHED: VGG-13 TFLITE vs. DMC ---\n",
      "============================================================\n",
      "       Method        |  Top-1 Acc (%)  |    Size (MB)   \n",
      "------------------------------------------------------------\n",
      "  TFLite (Float32)   |      74.63      |   38.09   \n",
      "   DMC (Float32)     |      74.63      |   38.10   \n",
      "  TFLite (Dynamic)   |      74.62      |    9.59   \n",
      "   DMC (Dynamic)     |      74.32      |    9.55   \n",
      "  TFLite (Static)    |      74.44      |    9.63   \n",
      "    DMC (Static)     |      74.32      |    9.55   \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Print Final Summary Table ---\n",
    "print(\"\\n\\n--- REPRODUCTION FINISHED: VGG-13 TFLITE vs. DMC ---\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Method':^20} | {'Top-1 Acc (%)':^15} | {'Size (MB)':^15}\")\n",
    "print(\"-\" * 60)\n",
    "for name, acc, size in results:\n",
    "    print(f\"{name:^20} | {acc * 100:^15.2f} | {size/(2**20):^10.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
