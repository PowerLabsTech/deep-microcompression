{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2730641c",
   "metadata": {},
   "source": [
    "# LeNet-5 Experiment Reproduction Guide\n",
    "\n",
    "This guide explains how to reproduce the LeNet-5 (Baseline, Pruned, and Quantized-Pruned) experiments from the \"Deep Microcompression\" paper.\n",
    "\n",
    "## Required File Structure\n",
    "\n",
    "This script assumes it is located within the original project's directory structure under the experiments directory. The development module must be accessible two levels up from this script.\n",
    "\n",
    "\n",
    "## What to Expect\n",
    "\n",
    "The script will run the full experiment, which involves three stages:\n",
    "\n",
    "1. Baseline Model: Trains the original LeNet-5 model (20 epochs with early stopping) and saves it as lenet5_state_dict.pth.\n",
    "\n",
    "1. Pruned Model: Loads the baseline weights, applies the optimal structured pruning (conv2d_1: 9, linear_0: 50), and retrains the model (20 epochs).\n",
    "\n",
    "1. Quantized-Pruned Model: Applies 4-bit static quantization to the pruned model and performs Quantization-Aware Training (QAT) (15 epochs).\n",
    "\n",
    "The script will print the Accuracy and Model Size for each of these three stages, allowing your supervisor to easily verify the results from Table 2 in your paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b666c2",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12010403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    from torch.utils import data\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "except ImportError:\n",
    "    %pip install torch torchvision tqdm\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    from torch.utils import data\n",
    "    from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the script is in 'project_root/experiments/reproduce_table1'\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "try:\n",
    "    from development import (\n",
    "        Sequential,\n",
    "        Conv2d,\n",
    "        BatchNorm2d,\n",
    "        ReLU,\n",
    "        MaxPool2d,\n",
    "        Flatten,\n",
    "        Linear,\n",
    "        EarlyStopper,\n",
    "        QuantizationGranularity,\n",
    "        QuantizationScheme\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import the 'development' module.\")\n",
    "    print(\"Please ensure this script is run from 'experiments/reproduce_table1/'\")\n",
    "    print(\"and the 'development' module is in the project root ('../../').\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335eb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for a GPU, defaults to the cpu\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# To load a trained model, to skip the initial training step\n",
    "BASELINE_MODEL_FILE = \"lenet5_state_dict.pth\"\n",
    "INPUT_SHAPE = (1, 28, 28)\n",
    "DATASET_DIR = \"../../Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUCKY_NUMBER = 25\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "# cuDNN determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3837a",
   "metadata": {},
   "source": [
    "### Getting the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load Data ---\n",
    "def get_data_loaders():\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.RandomCrop((24, 24)),\n",
    "        transforms.Resize(INPUT_SHAPE[1:]),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    mnist_train_dataset = datasets.MNIST(DATASET_DIR, train=True, download=True, transform=data_transform)\n",
    "    mnist_test_dataset = datasets.MNIST(DATASET_DIR, train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True, num_workers=os.cpu_count(), drop_last=False) # type: ignore\n",
    "    mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32, shuffle=False, num_workers=os.cpu_count(), drop_last=False) # type: ignore\n",
    "    \n",
    "    return mnist_train_loader, mnist_test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Training & Evaluation Functions ---\n",
    "def accuracy_fun(y_pred, y_true):\n",
    "    return (y_pred.argmax(dim=1) == y_true).to(torch.float).mean().item() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b09d4",
   "metadata": {},
   "source": [
    "### Defining and Training the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb803c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Model ---\n",
    "def get_baseline_model():\n",
    "    return Sequential(\n",
    "        Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=(2, 2, 2, 2), bias=True),\n",
    "        BatchNorm2d(num_features=6),\n",
    "        ReLU(),\n",
    "        MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "        BatchNorm2d(num_features=16),\n",
    "        ReLU(),\n",
    "        MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        Flatten(),\n",
    "        Linear(in_features=16*5*5, out_features=84, bias=True),\n",
    "        ReLU(),\n",
    "        Linear(in_features=84, out_features=10, bias=True)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "\n",
    "def train_baseline(model, train_loader, test_loader):\n",
    "    print(\"\\n--- STAGE 1: Training Baseline Model ---\")\n",
    "    if os.path.exists(BASELINE_MODEL_FILE):\n",
    "        print(f\"Loading existing baseline weights from {BASELINE_MODEL_FILE}...\")\n",
    "        model.load_state_dict(torch.load(BASELINE_MODEL_FILE, weights_only=True), strict=False)\n",
    "        model.to(DEVICE)\n",
    "        return model\n",
    "\n",
    "    print(f\"No baseline weights found. Training from scratch (up to 15 epochs)...\")\n",
    "    early_stopper = EarlyStopper(\n",
    "        monitor_metric=\"validation_loss\",\n",
    "        delta=1e-7,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizer_fun = optim.Adam(model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    model.fit(\n",
    "        train_loader, 15, \n",
    "        criterion_fun, optimizer_fun, lr_scheduler,\n",
    "        validation_dataloader=test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        callbacks=[early_stopper],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    print(f\"Saving baseline weights to {BASELINE_MODEL_FILE}...\")\n",
    "    torch.save(model.cpu().state_dict(), BASELINE_MODEL_FILE)\n",
    "    model.to(DEVICE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb974d",
   "metadata": {},
   "source": [
    "### Pruning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned(baseline_model, train_loader, test_loader):\n",
    "    print(\"\\n--- STAGE 2: Applying Pruning & Retraining ---\")\n",
    "    \n",
    "    # Pruning parameters from paper (Table 1 / Sec 4.1.1)\n",
    "    pruning_config = {\n",
    "        \"prune_channel\": {\n",
    "            \"sparsity\": {\n",
    "                \"conv2d_0\": 0,\n",
    "                \"conv2d_1\": 9,\n",
    "                \"linear_0\": 64\n",
    "            },\n",
    "            \"metric\": \"l2\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Applying pruning config: {pruning_config['prune_channel']['sparsity']}\")\n",
    "    \n",
    "    # Re-initialize model architecture with pruning\n",
    "    pruned_model = baseline_model.init_compress(pruning_config, INPUT_SHAPE).to(DEVICE)\n",
    "    \n",
    "    # Retrain (fine-tune) the pruned model\n",
    "    print(\"Retraining pruned model (15 epochs)...\")\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizer_fun = optim.SGD(pruned_model.parameters(), lr=1.e-3, weight_decay=5e-4, momentum=.9)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_fun, mode=\"min\", patience=1)\n",
    "\n",
    "    pruned_model.fit(\n",
    "        train_loader, 20, \n",
    "        criterion_fun, optimizer_fun, lr_scheduler,\n",
    "        validation_dataloader=test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        device=DEVICE\n",
    "    )\n",
    "    return pruned_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badce33f",
   "metadata": {},
   "source": [
    "### Quantizing and Bit Packing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_quantized_pruned(pruned_model, train_loader, test_loader):\n",
    "    print(\"\\n--- STAGE 3: Applying Quantization (QAT) & Retraining ---\")\n",
    "    \n",
    "    # Configs from paper (Table 2, 4-bit static) and notebook\n",
    "    pruning_config = {\n",
    "        \"prune_channel\": {\n",
    "            \"sparsity\": {\n",
    "                \"conv2d_0\": 0,\n",
    "                \"conv2d_1\": 9,\n",
    "                \"linear_0\": 64\n",
    "            },\n",
    "            \"metric\": \"l2\"\n",
    "        }\n",
    "    }\n",
    "    quantization_config = {\n",
    "        \"quantize\": {\n",
    "            \"scheme\": QuantizationScheme.STATIC,\n",
    "            \"granularity\": QuantizationGranularity.PER_TENSOR,\n",
    "            \"bitwidth\": 4\n",
    "        }\n",
    "    }\n",
    "    full_compression_config = {**pruning_config, **quantization_config}\n",
    "\n",
    "    print(f\"Applying quantization config: 4-bit, STATIC, PER_TENSOR\")\n",
    "    \n",
    "    # Get one batch of calibration data\n",
    "    calibration_data = next(iter(test_loader))[0].to(DEVICE)\n",
    "    \n",
    "    # Initialize compression for QAT\n",
    "    quantized_model = pruned_model.init_compress(\n",
    "        full_compression_config, \n",
    "        INPUT_SHAPE, \n",
    "        calibration_data\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Perform Quantization-Aware Training (15 epochs from paper Table 2)\n",
    "    print(\"Performing QAT (15 epochs)...\")\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizer_fun = optim.SGD(quantized_model.parameters(), lr=1.e-4, weight_decay=5e-4, momentum=.9)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_fun, mode=\"min\", patience=1)\n",
    "\n",
    "    quantized_model.fit(\n",
    "        train_loader, 15, \n",
    "        criterion_fun, optimizer_fun, lr_scheduler,\n",
    "        validation_dataloader=test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        device=DEVICE\n",
    "    )\n",
    "    return quantized_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1202d",
   "metadata": {},
   "source": [
    "### Baseline Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "train_loader, test_loader = get_data_loaders()\n",
    "\n",
    "# --- STAGE 1: BASELINE ---\n",
    "baseline_model = get_baseline_model()\n",
    "baseline_model = train_baseline(baseline_model, train_loader, test_loader)\n",
    "\n",
    "print(\"Evaluating baseline model...\")\n",
    "baseline_eval = baseline_model.evaluate(test_loader, {\"acc\": accuracy_fun}, device=DEVICE)\n",
    "print(f\"==> STAGE 1 (Baseline) COMPLETE ==\")\n",
    "print(f\"    Accuracy: {baseline_eval['acc']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e9cef",
   "metadata": {},
   "source": [
    "### Pruned Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- STAGE 2: PRUNED ---\n",
    "# Use a copy to keep the original baseline model clean\n",
    "pruned_model = train_pruned(baseline_model, train_loader, test_loader)\n",
    "\n",
    "print(\"Evaluating pruned model...\")\n",
    "pruned_eval = pruned_model.evaluate(test_loader, {\"acc\": accuracy_fun}, device=DEVICE)\n",
    "print(f\"\\n==> STAGE 2 (Pruned) COMPLETE ==\")\n",
    "print(f\"    Accuracy: {pruned_eval['acc']:.2f}%\")\n",
    "\n",
    "print(f\"\\n===> Layerwise Prunning Results:\")\n",
    "for i, (name, module) in enumerate(pruned_model.names_layers()):\n",
    "    if (\"conv2d\" in name) or (\"linear\" in name):\n",
    "        print(f\"    Layer name : {name}, Original size {baseline_model[i].get_size_in_bits()/(8*1024)} Reduced size {module.get_size_in_bits()/(8*1024)}:  Size Ratio: {(1 - module.get_size_in_bits()/baseline_model[i].get_size_in_bits())*100:.2f}%\") # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b8dd1",
   "metadata": {},
   "source": [
    "### Quantized and Bit-Packed Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STAGE 3: QUANTIZED-PRUNED ---\n",
    "quantized_model = train_quantized_pruned(pruned_model, train_loader, test_loader)\n",
    "\n",
    "print(\"Evaluating final quantized-pruned model...\")\n",
    "quantized_eval = quantized_model.evaluate(test_loader, {\"acc\": accuracy_fun}, device=DEVICE)\n",
    "print(f\"\\n==> STAGE 3 (Quantized-Pruned) COMPLETE ==\")\n",
    "print(f\"    Accuracy: {quantized_eval['acc']:.2f}%\")\n",
    "\n",
    "print(f\"\\n===> Layerwise Pruned and Quantized Results:\")\n",
    "for i, (name, module) in enumerate(quantized_model.names_layers()):\n",
    "    if (\"conv2d\" in name) or (\"linear\" in name):\n",
    "        print(f\"    Layer name : {name}, Original size {baseline_model[i].get_size_in_bits()/(8*1024):8.4f} Reduced size {module.get_size_in_bits()/(8*1024):8.4f}:  Size Ratio: {(1 - module.get_size_in_bits()/baseline_model[i].get_size_in_bits())*100:.2f}%\") # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cdfe5",
   "metadata": {},
   "source": [
    "### Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = baseline_model.fuse(device=DEVICE).get_size_in_bytes()\n",
    "pruned_size = pruned_model.fuse(device=DEVICE).get_size_in_bytes()\n",
    "quantized_size = quantized_model.fuse(device=DEVICE).get_size_in_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4be826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- REPRODUCTION FINISHED ---\")\n",
    "print(\"\\nFinal Results Summary:\")\n",
    "print(f\"Baseline:   {baseline_eval['acc']:.2f}% Acc, {original_size/1024:7.2f}KB\")\n",
    "print(f\"Pruned:     {pruned_eval['acc']:.2f}% Acc, {pruned_size/1024:7.2f}KB, {pruned_size/original_size*100:.2f}% of original\")\n",
    "print(f\"Quantized:  {quantized_eval['acc']:.2f}% Acc, {quantized_size/1024:7.2f}KB, {quantized_size/original_size*100:.2f}% of original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ardunio_config = {'conv2d_0':4,\n",
    "    'conv2d_1': 7,\n",
    "    'linear_0': 55,\n",
    "    'batchnorm2d_0': 0,\n",
    "    'relu_0': 0,\n",
    "    'maxpool2d_0': 0,\n",
    "    'batchnorm2d_1': 0,\n",
    "    'relu_1': 0,\n",
    "    'maxpool2d_1': 0,\n",
    "    'flatten_0': 0,\n",
    "    'relu_2': 0,\n",
    "    'linear_1': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_config = {\n",
    "    \"prune_channel\": {\n",
    "        \"sparsity\": ardunio_config,\n",
    "        \"metric\": \"l2\"\n",
    "    }\n",
    "}\n",
    "\n",
    "quantization_config = {\n",
    "    \"quantize\": {\n",
    "        \"scheme\": QuantizationScheme.STATIC,\n",
    "        \"granularity\": QuantizationGranularity.PER_TENSOR,\n",
    "        \"bitwidth\": 4\n",
    "    }\n",
    "}\n",
    "full_compression_config = {**pruning_config, **quantization_config}\n",
    "\n",
    "\n",
    "uno_pruned_model = train_pruned(lenet5_model, ardunio_config, mnist_train_loader, mnist_test_loader)\n",
    "uno_quantized_model = train_quantized_pruned(uno_pruned_model, ardunio_config, mnist_train_loader, mnist_test_loader)\n",
    "\n",
    "# # Get one batch of calibration data\n",
    "# loader_iter = iter(mnist_test_loader)\n",
    "# calibration_data = torch.concat([next(loader_iter)[0] for _ in range(5)], dim=0).to(DEVICE)\n",
    "\n",
    "# # Initialize compression for QAT\n",
    "# uno_model = lenet5_model.init_compress(\n",
    "#     full_compression_config, \n",
    "#     INPUT_SHAPE, \n",
    "#     calibration_data\n",
    "# ).to(DEVICE)\n",
    "\n",
    "fused_model = uno_quantized_model.fuse().to(DEVICE).eval()\n",
    "fused_model.convert_to_c(INPUT_SHAPE, \"uno_model\", arduino_uno_src_dir, arduino_uno_include_dir, test_input)\n",
    "fused_model.convert_to_c(INPUT_SHAPE, \"uno_model\", hp_src_dir, hp_include_dir, test_input)\n",
    "fused_model.get_max_workspace_arena(INPUT_SHAPE)\n",
    "# fused_model.output_quantize.apply(fused_model(test_input))\n",
    "# uno_quantized_model.evaluate(mnist_test_loader, {\"acc\": accuracy_fun}, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
